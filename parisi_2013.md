To put it in another way, algorithmic architecture has been unable to do away with a problem proper to computation: the problem of calculating infinite series of probabilities in a manner that also includes—and this is significant here—the probability of incomputability. 33

the randomness of data is at the core of computation, and yet that these data cannot be fully explained in either mathematical or physical terms. As will be discussed in the next section, these data are “quasi-mathematical,” as they can be formalized as probabilities and yet remain incomplete. 34

Beneath the surface of ubiquitous computation—a surface composed of too much information, too many direct connections and interactions that are too smooth, all of which take place between programmed objects— there remains a contagious architecture of infinite parts, unsynthesizable quantities, and uncountable randomness that explodes within and between any finite kernels. 75

The epochal challenge of programming cultures is to venture into the infinity of incomputable probabilities (infinite discrete unities that are bigger than the totality of the whole sequence of algorithmic instructions) that lies beyond both the digital ground and interactive empiricism. 77

It is suggested here that strategies of preemption do not only correspond to the harnessing of potentialities into already rehearsed possibilities, and to the reduction of potentials to set probabilities. On the contrary, I will argue that strategies of preemption also require that potentialities—or what Alfred North Whitehead calls “eternal objects”—become determined in existing actualities, which are understood here as algorithmic objects (in the form of codes, parameters, and protocols) that add new spatiotemporal relations or space events on the extensive continuum. 6

automated prehensions have unleashed incomputable probabilities into everyday culture. Postcybernetic control harnesses dysfunctions, errors, and crisis by axiomitizing the irreversible advance of randomness, but it also works to script uncertainties within the programming of relations. 116

Instead, I take Chaitin’s computational proof of Omega or infinite probabilities, which are at once computably enumerable and algorithmically random, to explain that the automation of data implies an irreversible encounter with incomputable probabilities.  This is to say that the automated operations of prehension, and the mechanical procedures of computers, have their own blind spots, anomalies, and alien logic of calculation, which far from being computational failures are instead to be taken as symptoms of algorithmic thought. This is the point at which the sequential order of algorithms gives way to the conceptual prehension of computational infinities, when algorithms process data beyond what has already been programmed.192


I now want to suggest that this peculiar mode of thought is not equivalent to a predictive model of probability (which would predict the future through the probabilities of the past), but instead needs to be understood in terms of speculative computation, which entails the probabilities of infinities. 194

Yet against this, and as I argued earlier, computation reveals that algorithms are actual entities imbued with discrete infinities that can also be defined as incomputable probabilities. From this standpoint, speculative computation specifically concerns an actual mode of thought that prehends objects of infinity or eternal objects while constructing the spatiotemporalities of the present. In other words, infinite objects are not outside computation: they are the indeterminate condition through which algorithms become actual modes of thought. Speculative computation, therefore, does not mean that algorithms project the present (or past) into the future, but rather that algorithms introduce discrete infinities into actualities. 175-176


